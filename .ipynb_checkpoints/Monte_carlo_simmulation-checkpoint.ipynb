{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc0417-1d17-4b47-b5d1-df6cdfd446f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install quandl\n",
    "#!pip install yfinance\n",
    "#!pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41aa329-db97-4a74-bc0a-d8bedbbd6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install nvidia::numba-cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77294641-098d-46d7-aaee-e80a68dec592",
   "metadata": {},
   "source": [
    "# User\n",
    "puedes corregir el codigo me da este error:\n",
    "NvvmSupportError: libNVVM cannot be found. Do `conda install cudatoolkit`:\n",
    "Could not find module 'nvvm.dll' (or one of its dependencies). Try using the full path with constructor syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb72a0-53a1-4e4f-8d06-40081fa3d5b8",
   "metadata": {},
   "source": [
    "# Assistant\n",
    "El error que estás viendo, `NvvmSupportError: libNVVM cannot be found`, indica que tu entorno de Python no puede encontrar la biblioteca NVVM, que es parte del toolkit de CUDA. Esto puede suceder si no tienes instalado el `cudatoolkit` o si la instalación no está configurada correctamente.\n",
    "\n",
    "Para corregir este error, puedes seguir estos pasos:\n",
    "\n",
    "1. **Instalar el `cudatoolkit`**: Abre tu terminal o consola de Anaconda y ejecuta el siguiente comando para instalar el `cudatoolkit`:\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eecb1e-f61d-4cc1-a3f4-2cf84da59183",
   "metadata": {},
   "source": [
    "bash\n",
    "   conda install cudatoolkit\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b8796-074b-4d26-a8b1-bb380e9938a1",
   "metadata": {},
   "source": [
    "\n",
    "2. **Verificar la instalación**: Asegúrate de que la instalación se haya completado sin errores. Puedes verificar si el `cudatoolkit` está instalado correctamente ejecutando:\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b0111-0f60-4beb-948b-07626749cf5d",
   "metadata": {},
   "source": [
    "bash\n",
    "   conda list cudatoolkit\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c9a327-e217-4514-a895-0a483636b351",
   "metadata": {},
   "source": [
    "\n",
    "3. **Reiniciar el entorno**: Después de la instalación, es recomendable reiniciar tu entorno de Jupyter Notebook o cualquier otro entorno que estés utilizando para asegurarte de que los cambios surtan efecto.\n",
    "\n",
    "4. **Verificar la configuración de CUDA**: Asegúrate de que tu sistema tenga los controladores de NVIDIA instalados y que sean compatibles con la versión del `cudatoolkit` que has instalado.\n",
    "\n",
    "Si después de seguir estos pasos sigues teniendo problemas, verifica que la variable de entorno `PATH` incluya la ruta a las bibliotecas de CUDA. \n",
    "\n",
    "Si necesitas más ayuda, no dudes en preguntar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65fe81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt #for setting starting and ending dates\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #for visualisation\n",
    "import scipy.stats as stats #for plots\n",
    "import plotly.offline as pyo\n",
    "import quandl\n",
    "import yfinance as yf #for fetching real time data of stocks\n",
    "import pylab\n",
    "import seaborn as sns #built on top of matplotlib and is useful in providing useful interface for showing results\n",
    "from datetime import datetime #for data retrival of MnC's finances\n",
    "from pandas_datareader import data \n",
    "\n",
    "pd.options.plotting.backend='plotly'\n",
    "pyo.init_notebook_mode(connected='True')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9994f45a",
   "metadata": {},
   "source": [
    "Here we imported all the packages need for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505af880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the begining and ending dates\n",
    "today=datetime.now()\n",
    "year_ago=datetime(today.year-1,today.month,today.day) #starting date= one yr prior to current date"
   ]
  },
  {
   "cell_type": "raw",
   "id": "770a7e2f",
   "metadata": {},
   "source": [
    "Next we set the current datetime to today's and the time duration to 1year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c47eca-b9dc-4f5b-b579-5fcee867f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWTR=pd.read_csv(\"TWTR.csv\")\n",
    "MET=pd.read_csv(\"MET.csv\")\n",
    "MSFT=pd.read_csv(\"MSFT.csv\")\n",
    "AMZN=pd.read_csv(\"AMZN.csv\")\n",
    "EBAY=pd.read_csv(\"EBAY.csv\")\n",
    "NFLX=pd.read_csv(\"NFLX.csv\")\n",
    "\n",
    "#SIX companies choosed for data extraction\n",
    "company_list=['TWTR','MET','MSFT','AMZN','EBAY','NFLX']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5acf92d6",
   "metadata": {},
   "source": [
    "Next, we fetch the financial data of several companies we are intrested in.\n",
    "We may also use yfinance to get real time data of stocks within the time frame (I have showed its use\n",
    "too, in the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWTR.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8979f19",
   "metadata": {},
   "source": [
    "It shows the first 5 columns of the financial record of the choosenn stock, it helps us to analyze how the data is categorised and understand it's distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "MET.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97627f06",
   "metadata": {},
   "source": [
    "We do the same for all stocks we had choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b42a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a423c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fcf7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EBAY.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "NFLX.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWTR.info()\n",
    "#column datatypes, data stored in dataframe, gives a brief summary of the insights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44d394f6",
   "metadata": {},
   "source": [
    "info() gives us more insights into the dataset, its dimensions, its class, number of entries etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6fb15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(TWTR['Adjusted Close'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af3b9303",
   "metadata": {},
   "source": [
    "Here our main focus is on \"Adjusted Close\" section of the data, it means the cash value of the last transacted price before the market closes. The adjusted closing price is attributed to anything that would affect the stock price after the market closes for the day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587370dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First',TWTR.Close[0],'End', TWTR.Close[2258]) \n",
    "#Here we can see how the prices varied, intial vs closing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d8f24",
   "metadata": {},
   "source": [
    "Above is the starting and ending price of the asset choosen within the timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b378afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also compute log returns as its time additive\n",
    "log_returns=np.log(TWTR.Close/TWTR.Close.shift(1)).dropna() #we also dropped the nans \n",
    "log_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f743b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_returns.mean() #take the mean of log_Rreturns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWTR.Close[0]*(np.exp(log_returns.mean()*len(log_returns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to calculate the same using simple returns and see how it compares\n",
    "simple_returns = TWTR.Close.pct_change(fill_method=None).dropna()\n",
    "simple_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_returns.mean() # calculate the mean of simple_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ea01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWTR.Close[0]*(np.prod([(1+Rt) for Rt in simple_returns]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbf7047",
   "metadata": {},
   "source": [
    "Above, we find the closing price of twitter using simple returns."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f06ff31f",
   "metadata": {},
   "source": [
    "As we see by simple returns the prediction is close to the actually closing price but not accurately close, also its very non-intutive to follow through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b0ee2-7c5d-4fea-a616-fd57f8575ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of log returns\n",
    "log_returns.plot(kind='hist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636a315-6e1f-433d-9242-f69bbebee444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calcular el histograma de los log returns\n",
    "count, bins = np.histogram(log_returns, bins=50, density=True)\n",
    "\n",
    "# Graficar el histograma con barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(log_returns, bins=50, density=True, alpha=0.6, color='skyblue', label='Histograma de Log Returns')\n",
    "\n",
    "# Dibujar el contorno del histograma\n",
    "plt.plot(bins[:-1], count, linestyle='-', color='darkblue', label='Contorno del Histograma')\n",
    "\n",
    "# Añadir título y etiquetas\n",
    "plt.title(\"Histograma de Log Returns con Línea de Contorno\")\n",
    "plt.xlabel(\"Log Returns\")\n",
    "plt.ylabel(\"Densidad de Frecuencia\")\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab57dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_returns.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc116e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take the best and the worst case and see the std deviation and the probability of occurances if its assumed to be normal\n",
    "log_returns_sorted=log_returns.tolist()\n",
    "log_returns_sorted.sort()\n",
    "# Here we sorted all the log returns according to their value,\n",
    "# to get the lowest and the highest case (the leftmost and the Rightmost case in the Histogram)\n",
    "\n",
    "worst=log_returns_sorted[0]\n",
    "best=log_returns_sorted[-1]\n",
    "\n",
    "std_worst=(worst-log_returns.mean())/log_returns.std()\n",
    "std_best=(best-log_returns.mean())/log_returns.std()\n",
    "# here we normalise it\n",
    "\n",
    "print('Std dev. worst %.2f best %.2f' %(std_worst,std_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45786354",
   "metadata": {},
   "source": [
    "# Testing for normality"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de716de0",
   "metadata": {},
   "source": [
    "Q-Q or Quantile-Quantile Plots\n",
    "\n",
    "It plots two sets of quantiles against one another i.e. theoritical quantiles against actual quantiles of the variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(log_returns, dist='norm', plot=pylab)\n",
    "print('Q-Q PLOT')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4af845fc",
   "metadata": {},
   "source": [
    "As we can see from here normally treating financial data as normally distributed is not a bad assumption for the most part, except for the tails. Which we can see from the plot as well, at the tails and heads there seems a deviation from normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT['Close'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6ac03-d629-4df3-b860-3e6be36e820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT['Adjusted Close'].plot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07449bbb",
   "metadata": {},
   "source": [
    "We do the same for other assets as well, it would help us to annalyse how it is varrying wrt days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f4bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NFLX['Adjusted Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MET['Adjusted Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EBAY['Adjusted Close'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b733362",
   "metadata": {},
   "source": [
    "We then incorporate moving averages to eliminate fluctuations and this process is called smoothing of time series. It reduces the amount of variations present in the data. The main advantage of SMA is that it offers a smoothed line, less prone to whipsawing. Its often favoured by traders operating on longer time frames such as daily or weekly charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b0072e-db3b-4c7f-9ef1-3e9ff7317701",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f4dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of days for which moving average will be calculated\n",
    "MA_days = list(range(1, 28, 4))\n",
    "for ma in MA_days:\n",
    "    ma_str = \"MA: {}\".format(ma)\n",
    "    TWTR[ma_str] = TWTR['Adjusted Close'].rolling(ma).mean()\n",
    "    MET[ma_str] = MET['Adjusted Close'].rolling(ma).mean()\n",
    "    MSFT[ma_str] = MSFT['Adjusted Close'].rolling(ma).mean()\n",
    "    AMZN[ma_str] = AMZN['Adjusted Close'].rolling(ma).mean()\n",
    "    NFLX[ma_str] = NFLX['Adjusted Close'].rolling(ma).mean()\n",
    "    EBAY[ma_str] = EBAY['Adjusted Close'].rolling(ma).mean()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f349e3c",
   "metadata": {},
   "source": [
    "This code calculates the moving averages (MA) for a given set of days ([1, 30]) for the 'Adj Close' price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphic(company, company_string, MA_days):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Plot the Adjusted Close price\n",
    "    plt.plot(company['Adjusted Close'], label='Adjusted Close')\n",
    "    \n",
    "    # Plot each moving average\n",
    "    for i in MA_days:\n",
    "        plt.plot(company[f'MA: {i}'], label=f'MA: {i}')\n",
    "    \n",
    "    # Setting the title and labels\n",
    "    plt.title(company_string)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    \n",
    "    # Show legend and grid\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0454847",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [ TWTR,MET, EBAY,NFLX, MSFT, AMZN]\n",
    "\n",
    "for i in range(len(data_list)):   \n",
    "    plot_graphic(data_list[i], company_list[i], MA_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268648c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns and draw distribution\n",
    "\n",
    "for i in range(len(data_list)):\n",
    "    data_list[i]['Daily Returns'] = data_list[i]['Adjusted Close'].pct_change()\n",
    "    sns.displot(data_list[i]['Daily Returns'].dropna(), bins=50, color='blue', kde=True)\n",
    "    plt.title(company_list[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming data_list is a list of dictionaries with 'Daily Returns' as a key and the values are pandas Series\n",
    "daily_returns_list = [data['Daily Returns'] for data in data_list]\n",
    "\n",
    "# Concatenate the daily return series along the columns axis\n",
    "stock_returns = pd.concat(daily_returns_list, axis=1)\n",
    "\n",
    "# Set the columns names to match the company_list\n",
    "stock_returns.columns = company_list\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "stock_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(stock_returns.dropna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build correlation matrix\n",
    "corr = stock_returns.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(corr, mask=mask,  square=True, linewidths=.5, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53afa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_income = stock_returns.mean() # Mean income for each stock\n",
    "cov_returns = stock_returns.cov() # Covariation \n",
    "count = len(stock_returns.columns)\n",
    "print(mean_income, cov_returns, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dca57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function, that generate random shares\n",
    "def randomPortfolio():\n",
    "    share = np.exp(np.random.randn(count))\n",
    "    share = share / share.sum()\n",
    "    return share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8347d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IncomePortfolio(Rand):\n",
    "    return np.matmul(mean_income.values, Rand)\n",
    "\n",
    "\n",
    "def RiskPortfolio(Rand):\n",
    "    return np.sqrt(np.matmul(np.matmul(Rand, cov_returns.values), Rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = 10000\n",
    "risk = np.zeros(combinations)\n",
    "income = np.zeros(combinations)\n",
    "portfolio = np.zeros((combinations, count))\n",
    "\n",
    "# Function, which create new combinations of shares\n",
    "for i in range(combinations):\n",
    "    rand = randomPortfolio()\n",
    "\n",
    "    portfolio[i, :] = rand\n",
    "    risk[i] = RiskPortfolio(rand)\n",
    "    income[i] = IncomePortfolio(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.scatter(risk * 100, income * 100, c=\"b\", marker=\".\")\n",
    "plt.xlabel(\"Risk\")\n",
    "plt.ylabel(\"Income\")\n",
    "plt.title(\"Portfolios\")\n",
    "MaxSharpRatio = np.argmax(income / risk)\n",
    "plt.scatter([risk[MaxSharpRatio] * 100], [income[MaxSharpRatio] * 100], c=\"r\", marker=\"o\", label=\"Max Sharp ratio\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40ca5638",
   "metadata": {},
   "source": [
    "The above plot generates a scatter plot where the x-axis represents the risk and the y-axis represents the income for multiple portfolios. It further highlights the portfolio with the maximum Sharpe ratio by adding a red dot at its corresponding risk and income values and including a legend to identify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3545b-d00c-42d8-ae40-b9a51e62bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max sharp ratios,\", portfolio[MaxSharpRatio])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e91777",
   "metadata": {},
   "source": [
    "Below we find the best portfolio out of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900aac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_port = portfolio[MaxSharpRatio]\n",
    "for i in range(len(company_list)):\n",
    "    print(\"{} : {}\".format(company_list[i], best_port[i]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a39967bc",
   "metadata": {},
   "source": [
    "It identifies the portfolio with the highest Sharpe ratio and then displays the allocation or weight assigned to each company in that portfolio. It allows us to see how the assets or companies are distributed within the best-performing portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 365\n",
    "dt = 1 / days\n",
    "# here I have divided by 365 but usually we do by 252 (the number of trading days)\n",
    "stock_returns.dropna(inplace=True)\n",
    "\n",
    "mu = stock_returns.mean()\n",
    "sigma = stock_returns.std()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca70670f",
   "metadata": {},
   "source": [
    "It calculates the average daily returns (mu) and the standard deviation of daily returns (sigma) for a stock based on the available data. These values are commonly used in financial analysis and risk assessment to understand the historical performance and volatility of a stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(start_price, days, mu, sigma):\n",
    "    price = np.zeros(days)\n",
    "    price[0] = start_price\n",
    "    \n",
    "    shock = np.zeros(days)\n",
    "    drift = np.zeros(days)\n",
    "    \n",
    "    for x in range(1, days):\n",
    "        shock[x] = np.random.normal(loc=mu * dt, scale=sigma*np.sqrt(dt))\n",
    "        drift[x] = mu * dt\n",
    "        \n",
    "        price[x] = price[x-1] + (price[x-1] * (drift[x] + shock[x]))\n",
    "        \n",
    "    return price"
   ]
  },
  {
   "cell_type": "raw",
   "id": "571f4468",
   "metadata": {},
   "source": [
    "The provided code snippet introduces a function named monte_carlo that employs the Monte Carlo method to simulate the future price of a stock.\n",
    "\n",
    "The monte_carlo function uses the Monte Carlo method to generate simulated stock prices for a specified number of days. It considers the initial stock price, average daily return, and standard deviation of daily returns. The function incorporates random shocks and drift components to calculate the simulated prices for each day.\n",
    "\n",
    "For the generation of random paths, I have used arithmetic Brownian motion, instead of this one can use geometric Brownian motion too.\n",
    "\n",
    "The more the variance the more the spread is, and the less the steepness is.In context to Monte Carlo Simulation, the random paths generated would be less differentiating if the variance is less and it would be more if the variance is more resulting in a flatter curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9099596-11c4-45dd-bd48-6c3c8a70ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e8529-079b-4238-8c46-ebbc09caba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start_price = 35.65\n",
    "n=10000\n",
    "sim = np.zeros(n)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "start = time.time()\n",
    "for i in range(n):\n",
    "    result = monte_carlo(start_price, days, mu['TWTR'], sigma['TWTR'])\n",
    "    sim[i] = result[days - 1]\n",
    "    plt.plot(result)    \n",
    "end = time.time()\n",
    "\n",
    "print(\"Tiempo transcurrido\", end-start)\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Monte Carlo analysis for Twitter')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4507ad74",
   "metadata": {},
   "source": [
    "This code performs a Monte Carlo analysis of Twitter's stock by predicting its future prices through 1000 simulations. The final prices from these simulations are stored in the 'sim' array and plotted. By doing so, the code offers potential insights into the future price range of Twitter's stock, as determined by the Monte Carlo simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34075779",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.hist(sim, bins=100)\n",
    "plt.figtext(0.6, 0.7, \"Mean: {} \\nStd: {} \\nStart Price: {}\".format(sim.mean(), sim.std(), start_price))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7736d601-5c15-4681-857d-7d2fd296b570",
   "metadata": {},
   "source": [
    "## Using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0c4a2-9757-4a0f-909e-4b8fd5464ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import time\n",
    "import numpy as np\n",
    "from numba import cuda, float32\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Parameters\n",
    "start_price = 35.65\n",
    "days = 365  # Number of days in the simulation\n",
    "mu_value = 0.0002  # Mean return (as a scalar)\n",
    "sigma_value = 0.02  # Volatility (as a scalar)\n",
    "num_simulations = 1000  # Number of Monte Carlo simulations\n",
    "\n",
    "# Define the CUDA kernel to run multiple simulations in parallel\n",
    "@cuda.jit\n",
    "def monte_carlo_cuda(start_price, days, mu, sigma, random_vals, simulations):\n",
    "    idx = cuda.grid(1)  # Get the index of the thread\n",
    "    if idx < simulations.shape[0]:\n",
    "        # Initialize the first price\n",
    "        current_price = start_price\n",
    "        for t in range(days):\n",
    "            # Get the precomputed random value from random_vals array\n",
    "            rand = random_vals[idx, t]\n",
    "            # Calculate the next price\n",
    "            current_price *= math.exp((mu - 0.5 * sigma**2) + sigma * rand)\n",
    "            # Store the result\n",
    "            simulations[idx, t] = current_price\n",
    "\n",
    "# Generate random values on the CPU\n",
    "random_vals = np.random.normal(0, 1, (num_simulations, days)).astype(np.float32)\n",
    "\n",
    "# Allocate space for the simulations on the device\n",
    "simulations = np.zeros((num_simulations, days), dtype=np.float32)\n",
    "d_random_vals = cuda.to_device(random_vals)\n",
    "d_simulations = cuda.to_device(simulations)\n",
    "\n",
    "# Adjust grid and block dimensions for CUDA\n",
    "threads_per_block = 1024\n",
    "blocks = (num_simulations + (threads_per_block - 1)) // threads_per_block\n",
    "\n",
    "# Start timing\n",
    "start = time.time()\n",
    "\n",
    "# Run Monte Carlo simulations in parallel on the GPU\n",
    "monte_carlo_cuda[blocks, threads_per_block](start_price, days, mu_value, sigma_value, d_random_vals, d_simulations)\n",
    "\n",
    "# Copy the results back to the host\n",
    "simulations = d_simulations.copy_to_host()\n",
    "\n",
    "# End timing\n",
    "end = time.time()\n",
    "\n",
    "# Print the elapsed time\n",
    "print(\"Tiempo transcurrido:\", end - start)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(num_simulations):\n",
    "    plt.plot(simulations[i])\n",
    "\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Monte Carlo analysis for Twitter')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68a6fb92",
   "metadata": {},
   "source": [
    "The provided code constructs a histogram to illustrate the distribution of the Twitter stock's simulated prices derived from the Monte Carlo simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a95b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_price = 907.34\n",
    "sim = np.zeros(1000)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(10000):\n",
    "    result = monte_carlo(start_price, days, mu['EBAY'], sigma['EBAY'])\n",
    "    sim[i] = result[days - 1]\n",
    "    plt.plot(result)\n",
    "    \n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Monte Carlo analysis for EBAY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db1f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.hist(sim, bins=100)\n",
    "plt.figtext(0.6, 0.7, \"Mean: {} \\nStd: {} \\nStart Price: {}\".format(sim.mean(), sim.std(), start_price))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_price = 300.95\n",
    "sim = np.zeros(1000)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(1000):\n",
    "    result = monte_carlo(start_price, days, mu['MSFT'], sigma['MSFT'])\n",
    "    sim[i] = result[days - 1]\n",
    "    plt.plot(result)\n",
    "    \n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Monte Carlo analysis for Microsoft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.hist(sim, bins=100)\n",
    "plt.figtext(0.6, 0.7, \"Mean: {} \\nStd: {} \\nStart Price: {}\".format(sim.mean(), sim.std(), start_price))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_price = 300.95\n",
    "sim = np.zeros(1000)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(1000):\n",
    "    result = monte_carlo(start_price, days, mu['AMZN'], sigma['AMZN'])\n",
    "    sim[i] = result[days - 1]\n",
    "    plt.plot(result)\n",
    "    \n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Monte Carlo analysis for Amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03233fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.hist(sim, bins=100)\n",
    "plt.figtext(0.6, 0.7, \"Mean: {} \\nStd: {} \\nStart Price: {}\".format(sim.mean(), sim.std(), start_price))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b600880",
   "metadata": {},
   "source": [
    "We did the same analysis for other stocks as well, which we discussed in detail for Twitter."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d9816d7",
   "metadata": {},
   "source": [
    "We can also extend this discussion to include risk factor along with it to incorporate more diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e579d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import more data\n",
    "df = yf.download(['AAPL', 'NKE', 'GOOGL', 'AMZN'], start='2015-01-01', end='2019-12-31')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted Closing price\n",
    "df = df['Adj Close']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d02ef3",
   "metadata": {},
   "source": [
    "To understand the columns and distribution of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba9f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Closing Price History\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.plot(df)\n",
    "plt.title('Close Price History')\n",
    "plt.xlabel('Date',fontsize =20)\n",
    "plt.ylabel('Price in USD',fontsize = 20)\n",
    "ax.legend(df.columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53858642",
   "metadata": {},
   "source": [
    "Plot to understand the adjusted closing price of all the assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bee77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log of percentage change\n",
    "cov_matrix = df.pct_change().apply(lambda x: np.log(1+x)).cov()\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly returns for individual companies\n",
    "ind_er = df.resample('YE').last().pct_change().mean()\n",
    "ind_er"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd23d2c8",
   "metadata": {},
   "source": [
    "Above we find the yearly returns for all the assets choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77532428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility is given by the annual standard deviation. \n",
    "# We multiply by 252 because there are 252 trading days/year.\n",
    "ann_sd = df.pct_change().apply(lambda x: np.log(1+x)).std().apply(lambda x: x*np.sqrt(252))\n",
    "ann_sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84415d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = pd.concat([ind_er, ann_sd], axis=1) # Creating a table for visualising returns and volatility of assets\n",
    "assets.columns = ['Returns', 'Volatility']\n",
    "assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b7df35",
   "metadata": {},
   "source": [
    "Volatility and Returns for all the assets have been found above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d7d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ret = [] # Define an empty array for portfolio returns\n",
    "p_vol = [] # Define an empty array for portfolio volatility\n",
    "p_weights = [] # Define an empty array for asset weights\n",
    "\n",
    "num_assets = len(df.columns)\n",
    "num_portfolios = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1fd818",
   "metadata": {},
   "source": [
    "Number of portfolios = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for portfolio in range(num_portfolios):\n",
    "    weights = np.random.random(num_assets)\n",
    "    weights = weights/np.sum(weights)\n",
    "    p_weights.append(weights)\n",
    "    returns = np.dot(weights, ind_er) # Returns are the product of individual expected returns of asset and its \n",
    "                                      # weights \n",
    "    p_ret.append(returns)\n",
    "    var = cov_matrix.mul(weights, axis=0).mul(weights, axis=1).sum().sum()# Portfolio Variance\n",
    "    sd = np.sqrt(var) # Daily standard deviation\n",
    "    ann_sd = sd*np.sqrt(250) # Annual standard deviation = volatility\n",
    "    p_vol.append(ann_sd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb34ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Returns':p_ret, 'Volatility':p_vol}\n",
    "\n",
    "for counter, symbol in enumerate(df.columns.tolist()):\n",
    "    #print(counter, symbol)\n",
    "    data[symbol+' weight'] = [w[counter] for w in p_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios=pd.DataFrame(data)                        \n",
    "portfolios.head() # Dataframe of the 100000 portfolios created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9232cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting efficient frontier\n",
    "portfolios.plot.scatter(x='Volatility', y='Returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_vol_port = portfolios.iloc[portfolios['Volatility'].idxmin()]\n",
    "# idxmin() gives us the minimum value in the column specified.                               \n",
    "min_vol_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db392055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the minimum volatility portfolio\n",
    "plt.subplots(figsize=[10,10])\n",
    "plt.scatter(portfolios['Volatility'], portfolios['Returns'],marker='o', s=10, alpha=0.3)\n",
    "plt.scatter(min_vol_port[1], min_vol_port[0], color='r', marker='*', s=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fcb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the optimal portfolio\n",
    "rf = 0.01 # risk factor\n",
    "optimal_risky_port = portfolios.iloc[((portfolios['Returns']-rf)/portfolios['Volatility']).idxmax()]\n",
    "optimal_risky_port"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16f931",
   "metadata": {},
   "source": [
    "Above is the weights associated with each asset of portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4497b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting optimal portfolio\n",
    "plt.subplots(figsize=(10, 10))\n",
    "plt.scatter(portfolios['Volatility'], portfolios['Returns'],marker='o', s=10, alpha=0.3)\n",
    "plt.scatter(min_vol_port[1], min_vol_port[0], color='r', marker='*', s=500)\n",
    "plt.scatter(optimal_risky_port[1], optimal_risky_port[0], color='g', marker='*', s=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e00f7",
   "metadata": {},
   "source": [
    "For the extras part refer the other juypter notebook, it includes an attempt approach via quantum gates. I have also added \n",
    "a file containing the recommendations and extras in the google drive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
